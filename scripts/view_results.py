#!/usr/bin/env python3
"""
æ£€æµ‹ç»“æœæŸ¥çœ‹å·¥å…·
ç”¨äºæµè§ˆå’Œåˆ†æä¿å­˜çš„æ£€æµ‹ç»“æœ
"""

import os
import json
import sys
from datetime import datetime
from typing import Dict, List, Any
import argparse


class ResultsViewer:
    """æ£€æµ‹ç»“æœæŸ¥çœ‹å™¨"""
    
    def __init__(self, results_path: str = "results"):
        """
        åˆå§‹åŒ–ç»“æœæŸ¥çœ‹å™¨
        
        Args:
            results_path: ç»“æœä¿å­˜è·¯å¾„
        """
        self.results_path = results_path
        
        if not os.path.exists(results_path):
            print(f"âŒ ç»“æœç›®å½•ä¸å­˜åœ¨: {results_path}")
            sys.exit(1)
    
    def list_dates(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ—¥æœŸ"""
        dates = []
        
        for item in os.listdir(self.results_path):
            item_path = os.path.join(self.results_path, item)
            if os.path.isdir(item_path) and item.count('-') == 2:  # YYYY-MM-DDæ ¼å¼
                dates.append(item)
        
        return sorted(dates, reverse=True)
    
    def list_streams(self, date: str) -> List[str]:
        """åˆ—å‡ºæŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰æµ"""
        date_path = os.path.join(self.results_path, date)
        
        if not os.path.exists(date_path):
            return []
        
        streams = []
        for item in os.listdir(date_path):
            item_path = os.path.join(date_path, item)
            if os.path.isdir(item_path):
                streams.append(item)
        
        return sorted(streams)
    
    def list_detections(self, date: str, stream_id: str) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæŒ‡å®šæ—¥æœŸå’Œæµçš„æ‰€æœ‰æ£€æµ‹ç»“æœ"""
        stream_path = os.path.join(self.results_path, date, stream_id)
        
        if not os.path.exists(stream_path):
            return []
        
        detections = []
        for item in os.listdir(stream_path):
            item_path = os.path.join(stream_path, item)
            if os.path.isdir(item_path):
                info_file = os.path.join(item_path, 'detection_info.json')
                if os.path.exists(info_file):
                    try:
                        with open(info_file, 'r', encoding='utf-8') as f:
                            detection_info = json.load(f)
                        
                        detections.append({
                            'folder': item,
                            'path': item_path,
                            'info': detection_info,
                            'timestamp': detection_info['basic_info']['timestamp'],
                            'object_count': detection_info['detection_results']['total_objects'],
                            'has_alarm': detection_info['alarm_info']['has_alarm'],
                            'alarm_level': detection_info['alarm_info']['alarm_level']
                        })
                    except Exception as e:
                        print(f"âš ï¸ è¯»å–æ£€æµ‹ä¿¡æ¯å¤±è´¥: {info_file}, {e}")
        
        # æŒ‰æ—¶é—´æˆ³æ’åº
        return sorted(detections, key=lambda x: x['timestamp'], reverse=True)
    
    def show_summary(self) -> None:
        """æ˜¾ç¤ºç»“æœæ€»è§ˆ"""
        print("ğŸ“Š æ£€æµ‹ç»“æœæ€»è§ˆ")
        print("=" * 50)
        
        dates = self.list_dates()
        if not dates:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ£€æµ‹ç»“æœ")
            return
        
        total_detections = 0
        total_alarms = 0
        
        for date in dates:
            streams = self.list_streams(date)
            date_detections = 0
            date_alarms = 0
            
            for stream_id in streams:
                detections = self.list_detections(date, stream_id)
                date_detections += len(detections)
                date_alarms += sum(1 for d in detections if d['has_alarm'])
            
            total_detections += date_detections
            total_alarms += date_alarms
            
            if date_detections > 0:
                print(f"ğŸ“… {date}: {date_detections} ä¸ªæ£€æµ‹ç»“æœ, {date_alarms} ä¸ªæŠ¥è­¦")
        
        print("-" * 50)
        print(f"ğŸ“ˆ æ€»è®¡: {total_detections} ä¸ªæ£€æµ‹ç»“æœ, {total_alarms} ä¸ªæŠ¥è­¦")
        print(f"ğŸ“ æ¶‰åŠæ—¥æœŸ: {len(dates)} å¤©")
    
    def show_date_details(self, date: str) -> None:
        """æ˜¾ç¤ºæŒ‡å®šæ—¥æœŸçš„è¯¦ç»†ä¿¡æ¯"""
        print(f"ğŸ“… {date} è¯¦ç»†ä¿¡æ¯")
        print("=" * 50)
        
        streams = self.list_streams(date)
        if not streams:
            print("âŒ è¯¥æ—¥æœŸæ²¡æœ‰æ£€æµ‹ç»“æœ")
            return
        
        for stream_id in streams:
            detections = self.list_detections(date, stream_id)
            alarms = sum(1 for d in detections if d['has_alarm'])
            
            print(f"\nğŸ¥ æµID: {stream_id}")
            print(f"   æ£€æµ‹ç»“æœ: {len(detections)} ä¸ª")
            print(f"   æŠ¥è­¦äº‹ä»¶: {alarms} ä¸ª")
            
            if detections:
                latest = detections[0]
                earliest = detections[-1]
                print(f"   æ—¶é—´èŒƒå›´: {earliest['timestamp']} ~ {latest['timestamp']}")
                
                # ç»Ÿè®¡æ£€æµ‹çš„ç›®æ ‡ç±»å‹
                class_stats = {}
                for detection in detections:
                    for obj in detection['info']['detection_results']['objects']:
                        class_name = obj['class_name']
                        class_stats[class_name] = class_stats.get(class_name, 0) + 1
                
                if class_stats:
                    print("   ç›®æ ‡ç»Ÿè®¡:", end="")
                    for class_name, count in class_stats.items():
                        print(f" {class_name}({count})", end="")
                    print()
    
    def show_detection_details(self, date: str, stream_id: str, detection_folder: str) -> None:
        """æ˜¾ç¤ºå…·ä½“æ£€æµ‹ç»“æœçš„è¯¦ç»†ä¿¡æ¯"""
        detection_path = os.path.join(self.results_path, date, stream_id, detection_folder)
        info_file = os.path.join(detection_path, 'detection_info.json')
        
        if not os.path.exists(info_file):
            print(f"âŒ æ£€æµ‹ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨: {info_file}")
            return
        
        try:
            with open(info_file, 'r', encoding='utf-8') as f:
                info = json.load(f)
            
            print(f"ğŸ” æ£€æµ‹ç»“æœè¯¦æƒ…")
            print("=" * 50)
            
            # åŸºæœ¬ä¿¡æ¯
            basic = info['basic_info']
            print(f"â° æ—¶é—´: {basic['timestamp']}")
            print(f"ğŸ¥ æµID: {basic['stream_id']}")
            print(f"ğŸ¬ å¸§å·: {basic['frame_id']}")
            print(f"âš¡ å¤„ç†æ—¶é—´: {basic['processing_time']:.3f}ç§’")
            print(f"ğŸ“¹ è§†é¢‘æº: {basic['video_source']}")
            
            # æ£€æµ‹ç»“æœ
            detection_results = info['detection_results']
            print(f"\nğŸ¯ æ£€æµ‹ç»“æœ: å…± {detection_results['total_objects']} ä¸ªç›®æ ‡")
            
            for obj in detection_results['objects']:
                print(f"  #{obj['id']} {obj['class_name']}")
                print(f"     ç½®ä¿¡åº¦: {obj['confidence']:.3f}")
                print(f"     ä½ç½®: ({obj['bbox']['x1']:.0f}, {obj['bbox']['y1']:.0f}) - "
                      f"({obj['bbox']['x2']:.0f}, {obj['bbox']['y2']:.0f})")
                print(f"     å°ºå¯¸: {obj['bbox']['width']:.0f} x {obj['bbox']['height']:.0f}")
                print(f"     é¢ç§¯: {obj['area']:.0f}")
            
            # æŠ¥è­¦ä¿¡æ¯
            alarm_info = info['alarm_info']
            if alarm_info['has_alarm']:
                print(f"\nğŸš¨ æŠ¥è­¦ä¿¡æ¯: {alarm_info['alarm_level']} çº§")
                for alarm_obj in alarm_info['alarm_objects']:
                    print(f"  æŠ¥è­¦ç›®æ ‡: {alarm_obj['class_name']} (ç½®ä¿¡åº¦: {alarm_obj['confidence']:.3f})")
            else:
                print(f"\nâœ… æ— æŠ¥è­¦")
            
            # æ–‡ä»¶ä¿¡æ¯
            print(f"\nğŸ“ ä¿å­˜æ–‡ä»¶:")
            files = os.listdir(detection_path)
            for file in sorted(files):
                file_path = os.path.join(detection_path, file)
                if os.path.isfile(file_path):
                    size = os.path.getsize(file_path)
                    print(f"  ğŸ“„ {file} ({size:,} bytes)")
                elif os.path.isdir(file_path):
                    sub_files = len(os.listdir(file_path))
                    print(f"  ğŸ“ {file}/ ({sub_files} ä¸ªæ–‡ä»¶)")
            
        except Exception as e:
            print(f"âŒ è¯»å–æ£€æµ‹ä¿¡æ¯å¤±è´¥: {e}")
    
    def search_by_class(self, class_name: str, date: str = None) -> List[Dict]:
        """æŒ‰ç›®æ ‡ç±»åˆ«æœç´¢æ£€æµ‹ç»“æœ"""
        print(f"ğŸ” æœç´¢ç›®æ ‡ç±»åˆ«: {class_name}")
        if date:
            print(f"ğŸ“… é™å®šæ—¥æœŸ: {date}")
        print("=" * 50)
        
        results = []
        dates_to_search = [date] if date else self.list_dates()
        
        for search_date in dates_to_search:
            streams = self.list_streams(search_date)
            
            for stream_id in streams:
                detections = self.list_detections(search_date, stream_id)
                
                for detection in detections:
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æŒ‡å®šç±»åˆ«
                    for obj in detection['info']['detection_results']['objects']:
                        if obj['class_name'].lower() == class_name.lower():
                            results.append({
                                'date': search_date,
                                'stream_id': stream_id,
                                'folder': detection['folder'],
                                'timestamp': detection['timestamp'],
                                'confidence': obj['confidence'],
                                'bbox': obj['bbox']
                            })
                            break
        
        if results:
            print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…ç»“æœ:")
            
            # æŒ‰æ—¶é—´æ’åº
            results.sort(key=lambda x: x['timestamp'], reverse=True)
            
            for result in results[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
                print(f"  ğŸ“… {result['date']} {result['timestamp']}")
                print(f"     æµ: {result['stream_id']}, ç½®ä¿¡åº¦: {result['confidence']:.3f}")
                print(f"     è·¯å¾„: {result['date']}/{result['stream_id']}/{result['folder']}")
                print()
            
            if len(results) > 20:
                print(f"... è¿˜æœ‰ {len(results) - 20} ä¸ªç»“æœæœªæ˜¾ç¤º")
        else:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„ç»“æœ")
    
    def cleanup_old_results(self, days: int = 30) -> None:
        """æ¸…ç†æ—§çš„æ£€æµ‹ç»“æœ"""
        print(f"ğŸ§¹ æ¸…ç† {days} å¤©å‰çš„æ£€æµ‹ç»“æœ")
        print("=" * 50)
        
        from datetime import datetime, timedelta
        
        cutoff_date = datetime.now() - timedelta(days=days)
        dates = self.list_dates()
        
        removed_count = 0
        
        for date_str in dates:
            try:
                date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                if date_obj < cutoff_date:
                    date_path = os.path.join(self.results_path, date_str)
                    
                    # è®¡ç®—è¦åˆ é™¤çš„æ–‡ä»¶æ•°
                    total_files = 0
                    for root, dirs, files in os.walk(date_path):
                        total_files += len(files)
                    
                    import shutil
                    shutil.rmtree(date_path)
                    removed_count += total_files
                    
                    print(f"ğŸ—‘ï¸ åˆ é™¤æ—¥æœŸ: {date_str} ({total_files} ä¸ªæ–‡ä»¶)")
                    
            except ValueError:
                print(f"âš ï¸ è·³è¿‡æ— æ•ˆæ—¥æœŸæ ¼å¼: {date_str}")
        
        print(f"âœ… æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {removed_count} ä¸ªæ–‡ä»¶")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ£€æµ‹ç»“æœæŸ¥çœ‹å·¥å…·')
    parser.add_argument('--results-path', default='results', help='ç»“æœä¿å­˜è·¯å¾„')
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # æ€»è§ˆå‘½ä»¤
    subparsers.add_parser('summary', help='æ˜¾ç¤ºç»“æœæ€»è§ˆ')
    
    # æ—¥æœŸè¯¦æƒ…å‘½ä»¤
    date_parser = subparsers.add_parser('date', help='æ˜¾ç¤ºæŒ‡å®šæ—¥æœŸçš„è¯¦æƒ…')
    date_parser.add_argument('date', help='æ—¥æœŸ (YYYY-MM-DD)')
    
    # æ£€æµ‹è¯¦æƒ…å‘½ä»¤
    detail_parser = subparsers.add_parser('detail', help='æ˜¾ç¤ºå…·ä½“æ£€æµ‹ç»“æœ')
    detail_parser.add_argument('date', help='æ—¥æœŸ (YYYY-MM-DD)')
    detail_parser.add_argument('stream_id', help='æµID')
    detail_parser.add_argument('folder', help='æ£€æµ‹ç»“æœæ–‡ä»¶å¤¹å')
    
    # æœç´¢å‘½ä»¤
    search_parser = subparsers.add_parser('search', help='æŒ‰ç±»åˆ«æœç´¢')
    search_parser.add_argument('class_name', help='ç›®æ ‡ç±»åˆ«åç§°')
    search_parser.add_argument('--date', help='é™å®šæœç´¢æ—¥æœŸ')
    
    # æ¸…ç†å‘½ä»¤
    cleanup_parser = subparsers.add_parser('cleanup', help='æ¸…ç†æ—§ç»“æœ')
    cleanup_parser.add_argument('--days', type=int, default=30, help='ä¿ç•™å¤©æ•°')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    viewer = ResultsViewer(args.results_path)
    
    if args.command == 'summary':
        viewer.show_summary()
    
    elif args.command == 'date':
        viewer.show_date_details(args.date)
    
    elif args.command == 'detail':
        viewer.show_detection_details(args.date, args.stream_id, args.folder)
    
    elif args.command == 'search':
        viewer.search_by_class(args.class_name, args.date)
    
    elif args.command == 'cleanup':
        viewer.cleanup_old_results(args.days)


if __name__ == "__main__":
    main()
